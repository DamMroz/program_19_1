Neural networks that are characterized by the interconnection of various neurons function with weights that change during the training of the model. By employing a specific architecture, the training of the model is quite fast and effective. An example is the input of a picture. The convolutional layer and pooling layer are used to obtain a prediction of the probabilities as the output of the model.
A convolution layer restricts the area of interest for each neuron. A kernel acts as a filter in this case. The result of such a model is a feature map that represents the occurrence or non-occurrence of the specific feature.
The pooling layer aggregates the results of the convolution layer by returning the maximum value (max pooling) or average value (average pooling), resulting in a significant decrease of the amount of data.
The fully connected layer flattens the weight matrix into a vector, which in turn results in the output of the model, leading to a prediction of the probabilities of belonging to a certain class.